{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T01:23:34.077158Z",
     "start_time": "2020-04-05T01:23:26.320452Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9wfP9iCg0r67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Bottleneck in /Users/Diven/opt/anaconda3/lib/python3.7/site-packages (1.2.1)\r\n",
      "Requirement already satisfied: numpy in /Users/Diven/opt/anaconda3/lib/python3.7/site-packages (from Bottleneck) (1.17.2)\r\n"
     ]
    }
   ],
   "source": [
    "#!pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
    "#!pip install fastai\n",
    "#!pip install HealthCheck\n",
    "#!pip install google-cloud-storage\n",
    "#!pip install google-cloud-logging\n",
    "\n",
    "!pip install Bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " {\n",
    "\t\"text\":\"food was good\"\n",
    "}\n",
    "\n",
    "http://0.0.0.0:5000/seclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:15:28.967698Z",
     "start_time": "2020-04-04T17:13:05.658576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "from flask import Flask, jsonify, request\n",
    "from healthcheck import HealthCheck\n",
    "#from google.cloud import logging\n",
    "\n",
    "import logging\n",
    "\n",
    "import google.cloud.logging\n",
    "\n",
    "client = google.cloud.logging.Client()\n",
    "client.setup_logging()\n",
    "\n",
    "app = Flask(__name__)\n",
    "path = Path('')\n",
    "learn = load_learner(path)\n",
    "\n",
    "#For flask\n",
    "#logging.basicConfig(filename=\"flask.log\", level=logging.DEBUG, format='%(asctime)s %(levelname)s %(name)s %(threadName)s : %(message)s')\n",
    "logging.info(\"Model and vocab loaded\")\n",
    "print(\"Model Loaded\")\n",
    "\n",
    "\n",
    "health = HealthCheck(app, \"/hcheck\")\n",
    "\n",
    "def healthcheck_func():\n",
    "    return True, \"Everything is up and running\"\n",
    "\n",
    "health.add_check(healthcheck_func)\n",
    "\n",
    "\n",
    "def predict_func(text):\n",
    "  result = learn.predict(text)\n",
    "  return result\n",
    "\n",
    "\n",
    "@app.route('/seclassifier', methods=['POST'])\n",
    "def predict_sentiment():\n",
    "    text = request.get_json()['text']\n",
    "    #print(text)\n",
    "    predictions = predict_func(text)\n",
    "    predictions=str(predictions[0])\n",
    "    #print(predictions)\n",
    "    app.logger.info(\"Text:\" + text +\"Prediction:\" + predictions)\n",
    "    return jsonify({'Text': text,'predictions':predictions})\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  app.run(host='0.0.0.0', port='8000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waitress import serve\n",
    "import Flask_model_deployment\n",
    "\n",
    "serve(Flask_model_deployment.app, port=8000, threads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flask_model_deployment import app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:58:38.227151Z",
     "start_time": "2020-04-03T01:58:37.153257Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Vwo9HIrAh-kY",
    "outputId": "83f69b3b-ceee-49c2-83ed-8da6c0d77d1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 5, tensor(4), tensor([0.1075, 0.0485, 0.0864, 0.3035, 0.4541]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
    "#!pip install fastai\n",
    "#from fastai.text import *\n",
    "\n",
    "path = Path('')\n",
    "learn = load_learner(path)\n",
    "learn.predict(\"if you are a taco lover, do visit this cafe, best tacos in town\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gcloud config set project model-deployment-273216\n",
    "\n",
    "gcloud config get-value project\n",
    "\n",
    "gsutil cp -r gs://review-rating-model/ .\n",
    "\n",
    "cd review-rating-model/\n",
    "\n",
    "ls -alrt\n",
    "\n",
    "gcloud builds submit --tag gcr.io/model-deployment-273216/saflask-gke .\n",
    "\n",
    "gcloud container clusters create flaskapp-gke --num-nodes 1 --enable-basic-auth --issue-client-certificate --zone us-west1-b --scopes https://www.googlea\n",
    "pis.com/auth/logging.write\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Flask model deployment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
